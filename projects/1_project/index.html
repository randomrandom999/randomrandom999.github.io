<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> project 1: hybrid images | Introduction to Computer Vision </title> <meta name="author" content=" "> <meta name="description" content="coming soon"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://randomrandom999.github.io/projects/1_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Introduction to Computer Vision </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/lectures/index.html">lectures </a> </li> <li class="nav-item "> <a class="nav-link" href="/resources/">resources </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">project 1: hybrid images</h1> <p class="post-description">coming soon</p> </header> <article> <p>&lt;!doctype html&gt;</p> <title>Project 1: Hybrid Images</title> <link href="http://fonts.googleapis.com/css?family=Lato&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css"> <link href="style.css" rel="stylesheet" type="text/css"> <main> <header> <h1>Project 1: Hybrid Images</h1> <figure> <img src="hybrid_image.jpg">&lt;/img&gt; <figcaption> Look at the image from very close and then very far (or if you can't move far away, just zoom out the page to shrink it and squint). What do you see? </figcaption> </figure> </header> <section id="keyInformation"> <h2>Key Information</h2> <table> <tr> <td><strong>Assigned</strong></td> <td>Tuesday, Jan 29, 2019 (Code accessible from <a href="https://github.com/cornelltechcs5670/Cornell-CS5670-2019" rel="external nofollow noopener" target="_blank">course GitHub repo</a>)</td> </tr> <tr class="importantInfo"> <td><strong>Due</strong></td> <td>Monday, Feb 11 on CMS by 11:59pm</td> </tr> <tr> <td><strong>Code Files to Submit</strong></td> <td><code>hybrid.py</code></td> </tr> <tr class="importantInfo"> <td><strong>Artifact Due</strong></td> <td>Wednesday, Feb 13 on CMS by 11:59pm</td> </tr> <tr> <td><strong>Artifact Files to Submit</strong></td> <td><code>README, left.png, right.png, hybrid.png</code></td> &lt;/li&gt; &lt;/table&gt; <br> This project <strong>must be done individually (groups of one).</strong> &lt;/section&gt; &lt;/section id="overview"&gt; <h2>Overview</h2> <p> The goal of this assignment is to write an image filtering function and use it to create <a href="http://cvcl.mit.edu/hybrid_gallery/gallery.html" rel="external nofollow noopener" target="_blank"> hybrid images</a> using a simplified version of the SIGGRAPH 2006 <a href="http://cvcl.mit.edu/publications/OlivaTorralb_Hybrid_Siggraph06.pdf" rel="external nofollow noopener" target="_blank"> paper</a> by Oliva, Torralba, and Schyns. <strong>Hybrid images</strong> are static images that change in interpretation as a function of the viewing distance. The basic idea is that high frequency tends to dominate perception when it is available, but, at a distance, only the low frequency (smooth) part of the signal can be seen. By blending the high frequency portion of one image with the low-frequency portion of another, you get a hybrid image that leads to different interpretations at different distances. </p> <p>You will use your <strong>own</strong> solution to create your <strong>own</strong> hybrid images, and the class will vote on the best hybrid image created. </p> <p> In the <a href="#downloads">Downloads</a> section below, we provide you with a tutorial on how to set up a python environment called <font color="red">cs5670_python_env</font> for you to run this project. We've set up this environment on the lab machines in the master studio. Apart from that, there is skeleton code for a user interface provided on <a href="https://github.com/cornelltechcs5670/Cornell-CS5670-2019/tree/master/Project1_Hybrid_Images" rel="external nofollow noopener" target="_blank"> github</a> along with a file <code>hybrid.py</code> that contains functions that you need to implement. We will walk you through the functions in the next section. If you have issues running the VM or the user interface, please post a question on Piazza, or visit a TA during his or her office hours. </p> &lt;/section&gt; <section id="details"> <h2>Implementation Details</h2> <p> This project is intended to familiarize you with Python, NumPy and image filtering. Once you have created an image filtering function, it is relatively straightforward to construct hybrid images. </p> <p> This project requires you to implement 5 functions each of which builds onto a previous function: </p> <ol> <li><code>cross_correlation_2d</code></li> <li><code>convolve_2d</code></li> <li><code>gaussian_blur_kernel_2d</code></li> <li><code>low_pass</code></li> <li><code>high_pass</code></li> </ol> <p> <strong>Image Filtering.</strong> Image filtering (or convolution) is a fundamental image processing tool. See chapter 3.2 of Szeliski and the lecture materials to learn about image filtering (specifically linear filtering). Numpy has numerous built in and efficient functions to perform image filtering, but you will be writing your own such function from scratch for this assignment. More specifically, you will implement <code>cross_correlation_2d</code>, followed by <code>convolve_2d</code> which would use <code>cross_correlation_2d</code>. </p> <p> <strong>Gaussian Blur.</strong> As you have seen in the lectures, there are a few different way to blur an image, for example taking an unweighted average of the neighboring pixels. Gaussian blur is a special kind of <em>weighted</em> averaging of neighboring pixels, and is described in the lecture slides. To implement Gaussian blur, you will implement a function <code>gaussian_blur_kernel_2d</code> that produces a kernel of a given <em>height</em> and <em>width</em> which can then be passed to <code>convolve_2d</code> from above, along with an image, to produce a blurred version of the image. </p> <p> <strong>High and Low Pass Filters.</strong> Recall that a low pass filter is one that removes the fine details from an image (or, really, any <em>signal</em>), whereas a high pass filter only retails the fine details, and gets rid of the coarse details from an image. Thus, using <strong> Gaussian blurring </strong> as described above, implement <code>high_pass</code> and <code>low_pass</code> functions. </p> <p> <strong>Hybrid Images.</strong> A hybrid image is the sum of a low-pass filtered version of the one image and a high-pass filtered version of a second image. There is a free parameter, which can be tuned for each image pair, which controls <em>how much</em> high frequency to remove from the first image and how much low frequency to leave in the second image. This is called the "cutoff-frequency". In the paper it is suggested to use two cutoff frequencies (one tuned for each image) and you are free to try that, as well. In the starter code, the cutoff frequency is controlled by changing the standard deviation (sigma) of the Gausian filter used in constructing the hybrid images. We provide you with the code for creating a hybrid image, using the functions described above. </p> <p> <strong class="importantInfo">Forbidden functions.</strong> For just this assignment, you are forbidden from using any Numpy, Scipy, OpenCV, or other preimplemented functions for filtering. This limitation will be lifted in future assignments, but for now, you should use for loops or Numpy vectorization to apply a kernel to each pixel in the image. The bulk of your code will be in <code>cross_correlation_2d</code>, and <code>gaussian_blur_kernel_2d</code> with the other functions using these functions either directly or through one of the other functions you implement. </p> <p> We have provided a GUI in <code>gui.py</code>, to help you debug your image filtering algorithm. To see a pre-labeled version of the sample images run: </p> <center><code>python gui.py -t resources/sample-correspondance.json -c resources/sample-config.json</code></center> <br> <p> We provide you with a pair of images that need to be <strong>aligned </strong> using the GUI. The code for alignment uses an affine transform to map the eyes to eyes and nose to nose, etc. as you specify on the GUI. We encourage you to create additional examples (e.g. change of expression, morph between different objects, change over time, etc.). See the <a href="http://cvcl.mit.edu/hybrid_gallery/gallery.html" rel="external nofollow noopener" target="_blank"> hybrid images project page</a> for some inspiration. The project page also contains materials from their <a href="http://cvcl.mit.edu/publications/publications.html" rel="external nofollow noopener" target="_blank"> Siggraph presentation</a>. </p> <p> For the example shown at the top of the page, the two original images look like this: </p> <img src="dog.jpg" width="395"> <img src="cat.jpg" width="395"> <p> The low-pass (blurred) and high-pass versions of these images look like below: </p> <img src="low_frequencies.jpg" width="395"> <img src="high_frequencies.jpg" width="395"> <p> Adding the high and low frequencies together gives you the image at the top of this page. If you're having trouble seeing the multiple interpretations of the image, a useful way to visualize the effect is to progressively downsample the hybrid image as is done below: </p> <img src="cat_hybrid_image_scales.jpg" width="800"> </section> <section id="Submission"> <h2> Submission </h2> <ul> <li> <strong>hybrid.py</strong>: Submit with all five functions implemented</li> <li> <strong>left.png, right.png</strong>: Submit the left and right images you used to create hybrid image. </li> <li> <strong>hybrid.png</strong>: Submit the hybrid image produced by using your implementation and left,right images</li> <li> <strong>README</strong> <ul> <li>Must contain high pass and low pass filter parameters(kernel size and kernel sigma) and Mix-in ratio.</li> <li>It should also contain which image's higher/lower frequencies are used.</li> <li> <strong>Optionally</strong> you can add comments on something interesting or different you did in the project.</li> </ul> </li> </ul> </section> <section id="downloads"> <h2> Downloads </h2> <ul> <li><a href="../cs5670_python_env/index.html">Tutorial on how to set up cs5670_python_env</a></li> <li>As an alternative to cs5670_python_env, we also provide a <a href="https://drive.google.com/file/d/16OYbcYNDL-T6RJbjU6ZXsv8zh5CxRUrD/view?usp=sharing" rel="external nofollow noopener" target="_blank"> ubuntu Virtual Machine (VM)</a> for you to use. Inside this VM, all dependent packages have been installed for you. Use <a href="https://www.virtualbox.org/" rel="external nofollow noopener" target="_blank">VirtualBox</a> to run it. (<strong class="importantInfo">VM Password: ubuntu</strong>) </li> <li>Skeleton code is on <a href="https://github.com/cornelltechcs5670/Cornell-CS5670-2019" rel="external nofollow noopener" target="_blank">github</a> </li> &lt;/ul&gt; &lt;/section&gt; <section> <h2> Python and Numpy Tutorials</h2> <p> We will use python programming language for all assignments in this course. In particular, we will use Numpy for scientific computing. If you are not farmilar with python and numpy, the following websites provide very good tutorials for them. If you have any questions related to python and numpy, please go to TA office hours or post questions on Piazza. </p> <ul> <li><a href="http://www.cs.cornell.edu/courses/cs4670/2016sp/lectures/lec06_numpy.pdf" rel="external nofollow noopener" target="_blank">Numpy primer</a></li> <li><a href="http://cs231n.github.io/python-numpy-tutorial/" rel="external nofollow noopener" target="_blank">Python Numpy Tutorial from Stanford CS231n</a></li> <li><a href="https://docs.scipy.org/doc/numpy-1.15.0/user/quickstart.html" rel="external nofollow noopener" target="_blank"> Official Numpy Quick Tutorial</a></li> <li><a href="https://docs.scipy.org/doc/numpy-1.15.0/user/numpy-for-matlab-users.html" rel="external nofollow noopener" target="_blank">Numpy for Matlab users</a></li> <li><a href="https://www.tutorialspoint.com/python/" rel="external nofollow noopener" target="_blank">Short Python Tutorial</a></li> </ul> </section> <section> <h2>Acknowledgements</h2> <p> Assignment based on versions developed by James Hays and Derek Hoiem. </p> </section> &lt;/main&gt; &lt;/body&gt; &lt;/html&gt; </ul></section> </tr> </table></section></main> </article> <h2>References</h2> <div class="publications"> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>